{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NohaWaly/Neural-Network-keras/blob/master/Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CrwmxChSFDY",
        "colab_type": "code",
        "outputId": "8540ecfc-d53e-4640-cdc9-aa7672522745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "! git clone https://github.com/ardamavi/Sign-Language-Digits-Dataset.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Sign-Language-Digits-Dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z6NvVTPsxHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#cv2 to read image, show and more\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "DataDir = \"Sign-Language-Digits-Dataset/Dataset\"\n",
        "ImgSize = 100\n",
        "\n",
        "Categories = [\"0\", \"1\",\"2\",\"3\", \"4\",\"5\",\"6\", \"7\",\"8\",\"9\"]\n",
        "data = []\n",
        "#iterate over 10 folders\n",
        "for category in Categories:  \n",
        "    # create path to each gesture \n",
        "    path = os.path.join(DataDir,category) \n",
        "    classNum = Categories.index(category)\n",
        "    #print(path)\n",
        "    # iterate over each image per each gesture \n",
        "    for img in os.listdir(path): \n",
        "        #print(img)\n",
        "        # convert to array\n",
        "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE) \n",
        "        # resize & divide with 255 to normalize data\n",
        "        resize_array = cv2.resize(img_array, (ImgSize, ImgSize))/255\n",
        "        #append to data\n",
        "        data.append([resize_array, classNum])\n",
        "    \n",
        "    \n",
        "\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VvjYNSA5fhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "       \n",
        "#shuffle data (msh kol class ykon wara b3d)\n",
        "random.shuffle(data)  \n",
        "#print(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdMUCOu2nlfz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "af181ef3-42d7-461c-85ad-ec5611b6379b"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in data:\n",
        "   X.append(features)\n",
        "   y.append(label)\n",
        "#to enter the model it should be np array\n",
        "X = np.array(X)\n",
        "y = np.array(y,dtype=int)\n",
        "\n",
        "#hot incoder\n",
        "#y = to_categorical(y)\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.48235294 0.49411765 0.50196078 ... 0.45882353 0.45490196 0.45098039]\n",
            "  [0.48627451 0.50196078 0.50588235 ... 0.46666667 0.45882353 0.45490196]\n",
            "  [0.49411765 0.50588235 0.51372549 ... 0.4745098  0.47058824 0.4627451 ]\n",
            "  ...\n",
            "  [0.48627451 0.49411765 0.50588235 ... 0.51764706 0.50980392 0.50196078]\n",
            "  [0.47058824 0.48235294 0.49411765 ... 0.50980392 0.50196078 0.49411765]\n",
            "  [0.47058824 0.4745098  0.48235294 ... 0.50588235 0.49411765 0.49019608]]\n",
            "\n",
            " [[0.46666667 0.4745098  0.47843137 ... 0.42352941 0.41568627 0.40784314]\n",
            "  [0.46666667 0.4745098  0.48235294 ... 0.42745098 0.41960784 0.41176471]\n",
            "  [0.46666667 0.47843137 0.49019608 ... 0.42352941 0.41568627 0.41176471]\n",
            "  ...\n",
            "  [0.36078431 0.36470588 0.37254902 ... 0.35294118 0.34901961 0.34509804]\n",
            "  [0.35686275 0.36078431 0.36862745 ... 0.34901961 0.34117647 0.3372549 ]\n",
            "  [0.35294118 0.36078431 0.36470588 ... 0.34509804 0.3372549  0.33333333]]\n",
            "\n",
            " [[0.51764706 0.52156863 0.52941176 ... 0.43921569 0.43529412 0.43137255]\n",
            "  [0.51764706 0.52156863 0.52941176 ... 0.44313725 0.43529412 0.43137255]\n",
            "  [0.51764706 0.5254902  0.53333333 ... 0.44705882 0.43921569 0.43529412]\n",
            "  ...\n",
            "  [0.45098039 0.45882353 0.46666667 ... 0.37647059 0.37254902 0.36862745]\n",
            "  [0.44705882 0.45490196 0.45882353 ... 0.36862745 0.36862745 0.36470588]\n",
            "  [0.44705882 0.45098039 0.45490196 ... 0.36470588 0.36470588 0.36078431]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.43921569 0.44705882 0.45098039 ... 0.44313725 0.43529412 0.42745098]\n",
            "  [0.43921569 0.45098039 0.45490196 ... 0.45098039 0.43921569 0.43137255]\n",
            "  [0.44313725 0.45490196 0.4627451  ... 0.45882353 0.44705882 0.43921569]\n",
            "  ...\n",
            "  [0.33333333 0.34117647 0.34509804 ... 0.36862745 0.36078431 0.36078431]\n",
            "  [0.3254902  0.32941176 0.33333333 ... 0.36862745 0.36470588 0.36078431]\n",
            "  [0.32156863 0.32156863 0.3254902  ... 0.35294118 0.34901961 0.34901961]]\n",
            "\n",
            " [[0.54509804 0.55686275 0.56078431 ... 0.5372549  0.52941176 0.5254902 ]\n",
            "  [0.54901961 0.56078431 0.56862745 ... 0.54901961 0.54117647 0.5372549 ]\n",
            "  [0.55294118 0.56470588 0.57254902 ... 0.54509804 0.5372549  0.52941176]\n",
            "  ...\n",
            "  [0.49411765 0.50196078 0.50588235 ... 0.49803922 0.49411765 0.48627451]\n",
            "  [0.48627451 0.49411765 0.49803922 ... 0.49019608 0.48627451 0.47843137]\n",
            "  [0.48235294 0.49019608 0.49411765 ... 0.49019608 0.48235294 0.47843137]]\n",
            "\n",
            " [[0.47058824 0.47843137 0.48235294 ... 0.42352941 0.41960784 0.41568627]\n",
            "  [0.4745098  0.47843137 0.48627451 ... 0.42745098 0.41960784 0.41568627]\n",
            "  [0.47843137 0.48627451 0.49019608 ... 0.42745098 0.42352941 0.41960784]\n",
            "  ...\n",
            "  [0.45490196 0.45882353 0.46666667 ... 0.43137255 0.42352941 0.42352941]\n",
            "  [0.44705882 0.45490196 0.4627451  ... 0.42745098 0.41960784 0.41568627]\n",
            "  [0.44705882 0.45098039 0.45882353 ... 0.42352941 0.41960784 0.41176471]]]\n",
            "[1 2 3 ... 7 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIpf3THweR9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spliting training & test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kpiGcCFjGTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_neural_network1():\n",
        "    #making the model\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "  model.compile(optimizer = tf.train.AdamOptimizer(),loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zADICzHZ-nLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_neural_network2():\n",
        "    #making the model\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "  model.compile(optimizer = tf.train.AdamOptimizer(),loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPljcCeG_xCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_neural_network3():\n",
        "    #making the model\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                      tf.keras.layers.Dense(360, activation=tf.nn.relu), \n",
        "                                      tf.keras.layers.Dense(360, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "  model.compile(optimizer = tf.train.AdamOptimizer(),loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI2MZeNA_xVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_neural_network4():\n",
        "    #making the model\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "  model.compile(optimizer = tf.train.AdamOptimizer(),loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDBPgcAxmEfH",
        "colab_type": "code",
        "outputId": "0392c45e-393e-4460-caed-3b9b9b09d5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_split = 4\n",
        "val_loss = np.zeros(n_split)\n",
        "val_acc = np.zeros(n_split)\n",
        "\n",
        "k_Fold = KFold(n_splits=4)\n",
        "models = [create_neural_network1,create_neural_network2,create_neural_network3,create_neural_network4]\n",
        "for x in range(4):\n",
        "  i=0\n",
        "  for train, validate in k_Fold.split(X_train, y_train):\n",
        "      model = models[x]()\n",
        "      model.fit(X_train[train], y_train[train], epochs=50)\n",
        "      val_loss[i], val_acc[i] = model.evaluate(X_train[validate],y_train[validate])\n",
        "      i+=1\n",
        "  print(\"Average Loss and Accuracy in Architecture\" +str(x+1))\n",
        "  print(val_loss.mean())\n",
        "  print(val_acc.mean()) \n",
        "  #evaluate the testing part\n",
        "  print(\"Evaluate testing part\")\n",
        "  model.evaluate(X_test, y_test)\n",
        "  #get predicted labels\n",
        "  y_predict = model.predict_classes(X_test)\n",
        "  #evaluate model using precision, fscore, & recall\n",
        "  print(classification_report(y_test, y_predict, target_names=Categories))\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1236 samples\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 0s 333us/sample - loss: 2.7547 - acc: 0.1052\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 2.3295 - acc: 0.1489\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 2.1916 - acc: 0.1780\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 241us/sample - loss: 2.0266 - acc: 0.2638\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 240us/sample - loss: 1.9465 - acc: 0.3066\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 1.7292 - acc: 0.3989\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 246us/sample - loss: 1.5244 - acc: 0.4547\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 0s 241us/sample - loss: 1.4023 - acc: 0.5008\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 257us/sample - loss: 1.3515 - acc: 0.5267\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 0s 250us/sample - loss: 1.3051 - acc: 0.5388\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 0s 239us/sample - loss: 1.2163 - acc: 0.5744\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 0s 235us/sample - loss: 1.0664 - acc: 0.6286\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 242us/sample - loss: 0.9986 - acc: 0.6699\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 0s 236us/sample - loss: 0.9486 - acc: 0.6642\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 0s 247us/sample - loss: 0.9282 - acc: 0.6796\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 247us/sample - loss: 1.0451 - acc: 0.6278\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 239us/sample - loss: 0.8136 - acc: 0.7298\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 235us/sample - loss: 0.8605 - acc: 0.7047\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 251us/sample - loss: 0.8609 - acc: 0.6926\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 0s 246us/sample - loss: 0.7393 - acc: 0.7540\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 0s 242us/sample - loss: 0.7032 - acc: 0.7573\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 240us/sample - loss: 0.7178 - acc: 0.7460\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 248us/sample - loss: 0.7475 - acc: 0.7524\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 0.6074 - acc: 0.7921\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 0.6697 - acc: 0.7629\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 252us/sample - loss: 0.7201 - acc: 0.7573\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 242us/sample - loss: 0.6672 - acc: 0.7654\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 234us/sample - loss: 0.8334 - acc: 0.7079\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 235us/sample - loss: 0.6474 - acc: 0.7807\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 0.6008 - acc: 0.7872\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 235us/sample - loss: 0.5539 - acc: 0.8042\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 231us/sample - loss: 0.5503 - acc: 0.8131\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 252us/sample - loss: 0.5639 - acc: 0.8115\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 0s 230us/sample - loss: 0.5153 - acc: 0.8172\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 240us/sample - loss: 0.4933 - acc: 0.8244\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 0s 232us/sample - loss: 0.5544 - acc: 0.8010\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 245us/sample - loss: 0.4176 - acc: 0.8560\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 235us/sample - loss: 0.3971 - acc: 0.8625\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 233us/sample - loss: 0.4431 - acc: 0.8398\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 247us/sample - loss: 0.4738 - acc: 0.8301\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 230us/sample - loss: 0.5100 - acc: 0.8155\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 220us/sample - loss: 0.3950 - acc: 0.8649\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 238us/sample - loss: 0.5238 - acc: 0.8107\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 234us/sample - loss: 0.4830 - acc: 0.8236\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 242us/sample - loss: 0.3486 - acc: 0.8827\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 244us/sample - loss: 0.3543 - acc: 0.8649\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 231us/sample - loss: 0.3848 - acc: 0.8633\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 235us/sample - loss: 0.3665 - acc: 0.8738\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 237us/sample - loss: 0.4263 - acc: 0.8479\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 240us/sample - loss: 0.3108 - acc: 0.8924\n",
            "413/413 [==============================] - 0s 158us/sample - loss: 0.6510 - acc: 0.7845\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 2.6865 - acc: 0.1132\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 236us/sample - loss: 2.2980 - acc: 0.1471\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 238us/sample - loss: 2.1044 - acc: 0.2288\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 1.9121 - acc: 0.3323\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 239us/sample - loss: 1.7007 - acc: 0.3638\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 1.4739 - acc: 0.4656\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 233us/sample - loss: 1.4835 - acc: 0.4608\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 1.3374 - acc: 0.5190\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 233us/sample - loss: 1.1766 - acc: 0.5853\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 246us/sample - loss: 1.2162 - acc: 0.5675\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 1.0541 - acc: 0.6378\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 234us/sample - loss: 1.0808 - acc: 0.6273\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 0.9805 - acc: 0.6742\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 237us/sample - loss: 0.9106 - acc: 0.6936\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.9279 - acc: 0.6863\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 224us/sample - loss: 0.8774 - acc: 0.7001\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 235us/sample - loss: 0.7559 - acc: 0.7429\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 225us/sample - loss: 0.7020 - acc: 0.7777\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 223us/sample - loss: 0.6382 - acc: 0.7801\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 219us/sample - loss: 0.7195 - acc: 0.7688\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 0.6136 - acc: 0.8044\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 232us/sample - loss: 0.6902 - acc: 0.7615\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.5151 - acc: 0.8383\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 226us/sample - loss: 0.5235 - acc: 0.8213\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 224us/sample - loss: 0.7332 - acc: 0.7445\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 246us/sample - loss: 0.6599 - acc: 0.7704\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 238us/sample - loss: 0.5510 - acc: 0.8092\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 238us/sample - loss: 0.4526 - acc: 0.8504\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 0.4491 - acc: 0.8504\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 0.5121 - acc: 0.8238\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 0.6629 - acc: 0.7696\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 0.6846 - acc: 0.7591\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.4435 - acc: 0.8488\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.4697 - acc: 0.8319\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 223us/sample - loss: 0.4930 - acc: 0.8302\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 225us/sample - loss: 0.3702 - acc: 0.8731\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 221us/sample - loss: 0.4559 - acc: 0.8456\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 225us/sample - loss: 0.4917 - acc: 0.8205\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.4371 - acc: 0.8545\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.3614 - acc: 0.8771\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 0.4376 - acc: 0.8416\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 0.3836 - acc: 0.8666\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 234us/sample - loss: 0.4269 - acc: 0.8521\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 230us/sample - loss: 0.3754 - acc: 0.8658\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.3849 - acc: 0.8577\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 236us/sample - loss: 0.3038 - acc: 0.8965\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.2587 - acc: 0.9070\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 233us/sample - loss: 0.3292 - acc: 0.8909\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 0.5975 - acc: 0.7995\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 234us/sample - loss: 0.3652 - acc: 0.8812\n",
            "412/412 [==============================] - 0s 154us/sample - loss: 0.9525 - acc: 0.7354\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 0s 295us/sample - loss: 2.6800 - acc: 0.1180\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 2.3187 - acc: 0.1714\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 247us/sample - loss: 2.1913 - acc: 0.1940\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 1.9641 - acc: 0.3226\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 1.7087 - acc: 0.3913\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 1.5241 - acc: 0.4559\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 1.4252 - acc: 0.4915\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 249us/sample - loss: 1.2832 - acc: 0.5424\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 1.2019 - acc: 0.5659\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 1.1989 - acc: 0.5829\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 1.3803 - acc: 0.5166\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 1.0952 - acc: 0.6306\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 1.0120 - acc: 0.6459\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 254us/sample - loss: 1.0094 - acc: 0.6354\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.8731 - acc: 0.7041\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 0.7570 - acc: 0.7445\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 0.8027 - acc: 0.7324\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 269us/sample - loss: 0.8028 - acc: 0.7195\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 254us/sample - loss: 0.7673 - acc: 0.7381\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 247us/sample - loss: 0.6934 - acc: 0.7688\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.5899 - acc: 0.8011\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 260us/sample - loss: 0.7319 - acc: 0.7470\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.6246 - acc: 0.8003\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 0.7129 - acc: 0.7470\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 265us/sample - loss: 0.5865 - acc: 0.8060\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.6878 - acc: 0.7720\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.5342 - acc: 0.8197\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.6073 - acc: 0.7866\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 0.8896 - acc: 0.6968\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.5769 - acc: 0.8084\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 0.4353 - acc: 0.8601\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.4624 - acc: 0.8432\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.6585 - acc: 0.7793\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 0.4497 - acc: 0.8504\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 0.4943 - acc: 0.8351\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 0.4559 - acc: 0.8375\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.3817 - acc: 0.8707\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 0.3767 - acc: 0.8747\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 0.4954 - acc: 0.8327\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 0.4962 - acc: 0.8238\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.4663 - acc: 0.8246\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 0.4306 - acc: 0.8561\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 249us/sample - loss: 0.3318 - acc: 0.8852\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 254us/sample - loss: 0.2873 - acc: 0.9022\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.3101 - acc: 0.8917\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 0.3067 - acc: 0.8981\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 0.4391 - acc: 0.8488\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.3609 - acc: 0.8771\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 247us/sample - loss: 0.3389 - acc: 0.8901\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 247us/sample - loss: 0.3167 - acc: 0.8957\n",
            "412/412 [==============================] - 0s 210us/sample - loss: 0.7248 - acc: 0.8034\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 0s 302us/sample - loss: 2.7316 - acc: 0.1067\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 2.3022 - acc: 0.1229\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 249us/sample - loss: 2.2914 - acc: 0.1342\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 2.2526 - acc: 0.1447\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 277us/sample - loss: 2.0805 - acc: 0.2264\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 1.9253 - acc: 0.2757\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 254us/sample - loss: 1.8950 - acc: 0.2781\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 1.6414 - acc: 0.3800\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 1.5737 - acc: 0.4050\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 1.5036 - acc: 0.4503\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 1.4695 - acc: 0.4462\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 1.4510 - acc: 0.4438\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 1.2767 - acc: 0.5206\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 1.3700 - acc: 0.4867\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 1.2815 - acc: 0.5319\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 1.1856 - acc: 0.5610\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 238us/sample - loss: 1.1976 - acc: 0.5521\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 1.1604 - acc: 0.5707\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 237us/sample - loss: 1.1803 - acc: 0.5384\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 1.1465 - acc: 0.5570\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 246us/sample - loss: 1.2120 - acc: 0.5255\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 1.1121 - acc: 0.5812\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 1.1161 - acc: 0.5845\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 238us/sample - loss: 1.1099 - acc: 0.5990\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 1.1960 - acc: 0.5344\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 1.0637 - acc: 0.5958\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 1.0728 - acc: 0.5942\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 239us/sample - loss: 1.0152 - acc: 0.5982\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 0.9770 - acc: 0.6192\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 1.0443 - acc: 0.6015\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.9460 - acc: 0.6548\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.9729 - acc: 0.6289\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.9437 - acc: 0.6500\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 232us/sample - loss: 0.9359 - acc: 0.6500\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.9235 - acc: 0.6540\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 222us/sample - loss: 1.1171 - acc: 0.5845\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 236us/sample - loss: 0.8802 - acc: 0.6645\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.8586 - acc: 0.6799\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 246us/sample - loss: 0.9602 - acc: 0.6289\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 232us/sample - loss: 0.9430 - acc: 0.6314\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 246us/sample - loss: 0.9594 - acc: 0.6306\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 227us/sample - loss: 0.8331 - acc: 0.6985\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 226us/sample - loss: 0.8485 - acc: 0.6831\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 0.8000 - acc: 0.7049\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 236us/sample - loss: 0.9432 - acc: 0.6419\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 231us/sample - loss: 0.7895 - acc: 0.7162\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.8201 - acc: 0.6880\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 240us/sample - loss: 0.8463 - acc: 0.6863\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 237us/sample - loss: 0.9754 - acc: 0.6338\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.9132 - acc: 0.6508\n",
            "412/412 [==============================] - 0s 197us/sample - loss: 1.1382 - acc: 0.6019\n",
            "Average Loss and Accuracy in Architecture1\n",
            "0.8666205898170037\n",
            "0.7313200980424881\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 96us/sample - loss: 1.1385 - acc: 0.5981\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.51      0.66        47\n",
            "           1       0.82      0.72      0.77        46\n",
            "           2       0.64      0.74      0.69        43\n",
            "           3       0.76      0.78      0.77        45\n",
            "           4       0.56      0.45      0.50        42\n",
            "           5       0.50      0.80      0.62        35\n",
            "           6       0.45      0.43      0.44        44\n",
            "           7       0.41      0.41      0.41        34\n",
            "           8       0.47      0.68      0.55        40\n",
            "           9       0.59      0.43      0.50        37\n",
            "\n",
            "    accuracy                           0.60       413\n",
            "   macro avg       0.61      0.60      0.59       413\n",
            "weighted avg       0.63      0.60      0.60       413\n",
            "\n",
            "Train on 1236 samples\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 0s 300us/sample - loss: 2.4627 - acc: 0.1133\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 261us/sample - loss: 2.3066 - acc: 0.1327\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 257us/sample - loss: 2.2465 - acc: 0.1440\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 259us/sample - loss: 2.1322 - acc: 0.1926\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 252us/sample - loss: 1.9144 - acc: 0.2646\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 250us/sample - loss: 1.7327 - acc: 0.3309\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 254us/sample - loss: 1.6194 - acc: 0.3600\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 0s 264us/sample - loss: 1.4660 - acc: 0.4385\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 259us/sample - loss: 1.5731 - acc: 0.3964\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 0s 263us/sample - loss: 1.3995 - acc: 0.4749\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 0s 256us/sample - loss: 1.4643 - acc: 0.4668\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 0s 265us/sample - loss: 1.3386 - acc: 0.4927\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 247us/sample - loss: 1.2947 - acc: 0.5057\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 0s 264us/sample - loss: 1.3923 - acc: 0.4717\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 0s 266us/sample - loss: 1.3769 - acc: 0.4644\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 258us/sample - loss: 1.3266 - acc: 0.4879\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 256us/sample - loss: 1.2654 - acc: 0.5316\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 271us/sample - loss: 1.1805 - acc: 0.5696\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 253us/sample - loss: 1.1078 - acc: 0.6076\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 0s 248us/sample - loss: 1.0949 - acc: 0.5930\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 0s 245us/sample - loss: 1.0839 - acc: 0.5939\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 242us/sample - loss: 1.0320 - acc: 0.6392\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 243us/sample - loss: 1.0847 - acc: 0.6076\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 238us/sample - loss: 1.1657 - acc: 0.5583\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 259us/sample - loss: 1.1125 - acc: 0.6028\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 244us/sample - loss: 1.0732 - acc: 0.6311\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 232us/sample - loss: 1.1059 - acc: 0.5930\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 256us/sample - loss: 1.1164 - acc: 0.6036\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 231us/sample - loss: 0.9814 - acc: 0.6424\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 242us/sample - loss: 0.9504 - acc: 0.6537\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 236us/sample - loss: 0.9335 - acc: 0.6634\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 247us/sample - loss: 1.0732 - acc: 0.6044\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 246us/sample - loss: 1.0849 - acc: 0.6052\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 0s 256us/sample - loss: 1.1490 - acc: 0.5801\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 244us/sample - loss: 0.9211 - acc: 0.6861\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 0s 248us/sample - loss: 0.8903 - acc: 0.6885\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 252us/sample - loss: 0.9332 - acc: 0.6739\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 253us/sample - loss: 0.9530 - acc: 0.6602\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 255us/sample - loss: 0.9234 - acc: 0.6691\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 245us/sample - loss: 0.9418 - acc: 0.6545\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 250us/sample - loss: 0.8603 - acc: 0.7104\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 252us/sample - loss: 0.9315 - acc: 0.6642\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 249us/sample - loss: 0.8420 - acc: 0.7006\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 250us/sample - loss: 0.9262 - acc: 0.6739\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 258us/sample - loss: 0.8274 - acc: 0.7095\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 250us/sample - loss: 0.9370 - acc: 0.6683\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 241us/sample - loss: 0.7608 - acc: 0.7395\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 264us/sample - loss: 0.7978 - acc: 0.7217\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 257us/sample - loss: 0.9184 - acc: 0.6748\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 247us/sample - loss: 0.8180 - acc: 0.7144\n",
            "413/413 [==============================] - 0s 199us/sample - loss: 0.9603 - acc: 0.6707\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 0s 335us/sample - loss: 2.4329 - acc: 0.1116\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 2.2846 - acc: 0.1665\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 267us/sample - loss: 2.1198 - acc: 0.2619\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 1.8520 - acc: 0.3226\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 1.6108 - acc: 0.3921\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 1.5499 - acc: 0.4155\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 253us/sample - loss: 1.3068 - acc: 0.5335\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 1.3454 - acc: 0.4980\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 1.2142 - acc: 0.5441\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 260us/sample - loss: 1.1495 - acc: 0.5861\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 241us/sample - loss: 1.1806 - acc: 0.5627\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 1.0230 - acc: 0.6395\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 1.1228 - acc: 0.5804\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.9656 - acc: 0.6815\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 1.0453 - acc: 0.6200\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 0.9482 - acc: 0.6645\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 239us/sample - loss: 0.9361 - acc: 0.6677\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 239us/sample - loss: 0.9290 - acc: 0.6783\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 248us/sample - loss: 0.7383 - acc: 0.7478\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 0.9278 - acc: 0.6718\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 0.6699 - acc: 0.7599\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 0.6688 - acc: 0.7664\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.7631 - acc: 0.7421\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 0.7196 - acc: 0.7591\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 0.7558 - acc: 0.7405\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 249us/sample - loss: 0.6573 - acc: 0.7736\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 242us/sample - loss: 0.5484 - acc: 0.8222\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.5775 - acc: 0.7955\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 0.6374 - acc: 0.7809\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.5539 - acc: 0.8108\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 272us/sample - loss: 0.6634 - acc: 0.7631\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 253us/sample - loss: 0.6579 - acc: 0.7745\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 0.4818 - acc: 0.8416\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.5350 - acc: 0.8205\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 249us/sample - loss: 0.5824 - acc: 0.7979\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 253us/sample - loss: 0.6164 - acc: 0.7801\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 253us/sample - loss: 0.5814 - acc: 0.7963\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 0.4480 - acc: 0.8448\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.4436 - acc: 0.8424\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.4463 - acc: 0.8359\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 251us/sample - loss: 0.4474 - acc: 0.8375\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 267us/sample - loss: 0.3826 - acc: 0.8755\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 0.4310 - acc: 0.8553\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 245us/sample - loss: 0.4224 - acc: 0.8610\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 0.5538 - acc: 0.8068\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 0.3600 - acc: 0.8892\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 0.3874 - acc: 0.8674\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 247us/sample - loss: 0.4754 - acc: 0.8222\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.3708 - acc: 0.8707\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.3024 - acc: 0.8868\n",
            "412/412 [==============================] - 0s 219us/sample - loss: 0.7550 - acc: 0.7816\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 0s 342us/sample - loss: 2.4880 - acc: 0.1293\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 2.3242 - acc: 0.1318\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 2.2614 - acc: 0.1649\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 2.0830 - acc: 0.2393\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 1.8042 - acc: 0.3331\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 282us/sample - loss: 1.6810 - acc: 0.3622\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 268us/sample - loss: 1.5699 - acc: 0.4276\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 1.3883 - acc: 0.4915\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 283us/sample - loss: 1.2885 - acc: 0.5222\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 1.1975 - acc: 0.5651\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 1.2138 - acc: 0.5635\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 268us/sample - loss: 1.0414 - acc: 0.6306\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 260us/sample - loss: 1.1054 - acc: 0.6152\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 244us/sample - loss: 1.0139 - acc: 0.6411\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 0.9795 - acc: 0.6403\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 253us/sample - loss: 0.9420 - acc: 0.6766\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.8159 - acc: 0.7098\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 253us/sample - loss: 0.9486 - acc: 0.6831\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 273us/sample - loss: 0.7365 - acc: 0.7332\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.6711 - acc: 0.7850\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 0.6907 - acc: 0.7599\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.6879 - acc: 0.7615\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.8648 - acc: 0.6993\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 255us/sample - loss: 0.7550 - acc: 0.7429\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 0.6671 - acc: 0.7704\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 0.6657 - acc: 0.7688\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 0.5597 - acc: 0.8068\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 269us/sample - loss: 0.5963 - acc: 0.7914\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.5246 - acc: 0.8302\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.6597 - acc: 0.7639\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 0.5423 - acc: 0.8133\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 0.4773 - acc: 0.8375\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 0.4243 - acc: 0.8513\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 0.4576 - acc: 0.8391\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 0.5929 - acc: 0.7922\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 268us/sample - loss: 0.4877 - acc: 0.8343\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.3906 - acc: 0.8545\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 254us/sample - loss: 0.4261 - acc: 0.8545\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.3350 - acc: 0.8852\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 0.3279 - acc: 0.8884\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 0.4623 - acc: 0.8391\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 0.5177 - acc: 0.8141\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 0.4416 - acc: 0.8424\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.4316 - acc: 0.8504\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 0.3710 - acc: 0.8820\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.3235 - acc: 0.8901\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 252us/sample - loss: 0.4724 - acc: 0.8335\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 267us/sample - loss: 0.3934 - acc: 0.8634\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.3078 - acc: 0.8933\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 273us/sample - loss: 0.2377 - acc: 0.9248\n",
            "412/412 [==============================] - 0s 232us/sample - loss: 0.9490 - acc: 0.7451\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 0s 355us/sample - loss: 2.4919 - acc: 0.1027\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 276us/sample - loss: 2.3113 - acc: 0.1253\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 2.2422 - acc: 0.1544\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 2.0761 - acc: 0.2555\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 1.9105 - acc: 0.2813\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 268us/sample - loss: 1.6803 - acc: 0.3897\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 1.5284 - acc: 0.4276\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 268us/sample - loss: 1.5099 - acc: 0.4438\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 243us/sample - loss: 1.3666 - acc: 0.4988\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 270us/sample - loss: 1.2260 - acc: 0.5465\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 1.2338 - acc: 0.5715\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 1.1392 - acc: 0.6047\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 254us/sample - loss: 1.0947 - acc: 0.6144\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 271us/sample - loss: 1.1289 - acc: 0.6015\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 257us/sample - loss: 0.9347 - acc: 0.6815\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 1.0558 - acc: 0.6168\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 282us/sample - loss: 1.0077 - acc: 0.6395\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 0.9116 - acc: 0.6791\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 0.9041 - acc: 0.7033\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 277us/sample - loss: 0.7964 - acc: 0.7276\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 267us/sample - loss: 0.8479 - acc: 0.6920\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 280us/sample - loss: 0.8088 - acc: 0.7276\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 273us/sample - loss: 0.8711 - acc: 0.7154\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 271us/sample - loss: 0.7876 - acc: 0.7203\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 270us/sample - loss: 0.6777 - acc: 0.7728\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 272us/sample - loss: 0.6642 - acc: 0.7801\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.6469 - acc: 0.7842\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 0.6605 - acc: 0.7664\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 0.6590 - acc: 0.7850\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 280us/sample - loss: 0.5988 - acc: 0.7833\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 260us/sample - loss: 0.5673 - acc: 0.8060\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 305us/sample - loss: 0.5242 - acc: 0.8222\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 265us/sample - loss: 0.5989 - acc: 0.7906\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 284us/sample - loss: 0.6301 - acc: 0.7825\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.7013 - acc: 0.7518\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.6223 - acc: 0.7712\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.4919 - acc: 0.8335\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.4502 - acc: 0.8432\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 269us/sample - loss: 0.4569 - acc: 0.8310\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 265us/sample - loss: 0.5369 - acc: 0.8238\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 259us/sample - loss: 0.5151 - acc: 0.8254\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 249us/sample - loss: 0.6236 - acc: 0.7817\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 0.6417 - acc: 0.7672\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 0.5819 - acc: 0.8092\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 263us/sample - loss: 0.4270 - acc: 0.8585\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 0.5742 - acc: 0.7963\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.3669 - acc: 0.8795\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 0.4849 - acc: 0.8270\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 256us/sample - loss: 0.3753 - acc: 0.8763\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 261us/sample - loss: 0.3903 - acc: 0.8504\n",
            "412/412 [==============================] - 0s 253us/sample - loss: 0.8077 - acc: 0.7670\n",
            "Average Loss and Accuracy in Architecture2\n",
            "0.8680079978905803\n",
            "0.7410978674888611\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 105us/sample - loss: 0.6858 - acc: 0.7748\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.89        47\n",
            "           1       0.89      0.72      0.80        46\n",
            "           2       0.91      0.72      0.81        43\n",
            "           3       0.95      0.82      0.88        45\n",
            "           4       0.68      0.62      0.65        42\n",
            "           5       0.82      0.91      0.86        35\n",
            "           6       0.78      0.73      0.75        44\n",
            "           7       0.55      0.65      0.59        34\n",
            "           8       0.58      0.82      0.68        40\n",
            "           9       0.82      0.84      0.83        37\n",
            "\n",
            "    accuracy                           0.77       413\n",
            "   macro avg       0.78      0.77      0.77       413\n",
            "weighted avg       0.79      0.77      0.78       413\n",
            "\n",
            "Train on 1236 samples\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 1s 775us/sample - loss: 3.5989 - acc: 0.1084\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 1s 673us/sample - loss: 2.2827 - acc: 0.1505\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 1s 706us/sample - loss: 2.1635 - acc: 0.2209\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 1s 715us/sample - loss: 1.9796 - acc: 0.2840\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 1s 700us/sample - loss: 1.7534 - acc: 0.3754\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 1s 697us/sample - loss: 1.7356 - acc: 0.3786\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 1s 671us/sample - loss: 1.5260 - acc: 0.4426\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 1s 681us/sample - loss: 1.4659 - acc: 0.4668\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 1s 672us/sample - loss: 1.3509 - acc: 0.5267\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 1s 669us/sample - loss: 1.3269 - acc: 0.4968\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 1s 677us/sample - loss: 1.2400 - acc: 0.5599\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 1s 676us/sample - loss: 1.2389 - acc: 0.5291\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 1s 690us/sample - loss: 1.1635 - acc: 0.5841\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 1s 673us/sample - loss: 1.1139 - acc: 0.6173\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 1s 683us/sample - loss: 1.0066 - acc: 0.6529\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 1s 700us/sample - loss: 0.9657 - acc: 0.6545\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 1s 681us/sample - loss: 0.8680 - acc: 0.7104\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 1s 683us/sample - loss: 0.8821 - acc: 0.6901\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 1s 668us/sample - loss: 0.9256 - acc: 0.6812\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 1s 676us/sample - loss: 0.8703 - acc: 0.6917\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 1s 694us/sample - loss: 0.7552 - acc: 0.7354\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 1s 680us/sample - loss: 0.7157 - acc: 0.7654\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 1s 699us/sample - loss: 0.7197 - acc: 0.7605\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 1s 699us/sample - loss: 0.6231 - acc: 0.7994\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 1s 697us/sample - loss: 0.7713 - acc: 0.7354\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 1s 694us/sample - loss: 0.6322 - acc: 0.7896\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 1s 692us/sample - loss: 0.6672 - acc: 0.7807\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 1s 690us/sample - loss: 0.7224 - acc: 0.7460\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 1s 739us/sample - loss: 0.6837 - acc: 0.7735\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 1s 702us/sample - loss: 0.5997 - acc: 0.7953\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 1s 713us/sample - loss: 0.6842 - acc: 0.7638\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 1s 715us/sample - loss: 0.6222 - acc: 0.7767\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 1s 700us/sample - loss: 0.4637 - acc: 0.8374\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 1s 683us/sample - loss: 0.4078 - acc: 0.8697\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 1s 684us/sample - loss: 0.4839 - acc: 0.8390\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 1s 669us/sample - loss: 0.4613 - acc: 0.8471\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 1s 674us/sample - loss: 0.6104 - acc: 0.7985\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 1s 677us/sample - loss: 0.4562 - acc: 0.8463\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 1s 675us/sample - loss: 0.4685 - acc: 0.8341\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 1s 665us/sample - loss: 0.6391 - acc: 0.7856\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 1s 700us/sample - loss: 0.5494 - acc: 0.8163\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 1s 675us/sample - loss: 0.3826 - acc: 0.8819\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 1s 678us/sample - loss: 0.3345 - acc: 0.8867\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 1s 673us/sample - loss: 0.3422 - acc: 0.8867\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 1s 667us/sample - loss: 0.3313 - acc: 0.8900\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 1s 690us/sample - loss: 0.4100 - acc: 0.8552\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 1s 687us/sample - loss: 0.3622 - acc: 0.8730\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 1s 692us/sample - loss: 0.4490 - acc: 0.8519\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 1s 691us/sample - loss: 0.4492 - acc: 0.8374\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 1s 692us/sample - loss: 0.3513 - acc: 0.8835\n",
            "413/413 [==============================] - 0s 374us/sample - loss: 0.6631 - acc: 0.8015\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 1s 746us/sample - loss: 3.3422 - acc: 0.1221\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 1s 711us/sample - loss: 2.5187 - acc: 0.1196\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 1s 664us/sample - loss: 2.1971 - acc: 0.1973\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 1s 662us/sample - loss: 2.0396 - acc: 0.2724\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 1s 660us/sample - loss: 1.8716 - acc: 0.3040\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 1s 657us/sample - loss: 1.7008 - acc: 0.3953\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 1s 653us/sample - loss: 1.5753 - acc: 0.4293\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 1s 663us/sample - loss: 1.5504 - acc: 0.4204\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 1s 671us/sample - loss: 1.4095 - acc: 0.4891\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 1s 659us/sample - loss: 1.2597 - acc: 0.5311\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 1s 668us/sample - loss: 1.1182 - acc: 0.5958\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 1s 679us/sample - loss: 1.1495 - acc: 0.5885\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 1s 690us/sample - loss: 1.1190 - acc: 0.6120\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 1s 671us/sample - loss: 1.0709 - acc: 0.6233\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 1s 672us/sample - loss: 0.9934 - acc: 0.6467\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 1s 671us/sample - loss: 0.9263 - acc: 0.6985\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 1s 659us/sample - loss: 0.8470 - acc: 0.7146\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 1s 668us/sample - loss: 1.0686 - acc: 0.6160\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 1s 666us/sample - loss: 0.8374 - acc: 0.7235\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 1s 667us/sample - loss: 0.8482 - acc: 0.7009\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 1s 669us/sample - loss: 0.8172 - acc: 0.7251\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 1s 661us/sample - loss: 0.7205 - acc: 0.7591\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 1s 671us/sample - loss: 0.7224 - acc: 0.7534\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 1s 666us/sample - loss: 0.7435 - acc: 0.7454\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 1s 681us/sample - loss: 0.8024 - acc: 0.7316\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 1s 661us/sample - loss: 0.5933 - acc: 0.7995\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 1s 638us/sample - loss: 0.5912 - acc: 0.7955\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 1s 671us/sample - loss: 0.5930 - acc: 0.7874\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 1s 649us/sample - loss: 0.6775 - acc: 0.7542\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 1s 649us/sample - loss: 0.4825 - acc: 0.8375\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 1s 641us/sample - loss: 0.4801 - acc: 0.8278\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 1s 646us/sample - loss: 0.5119 - acc: 0.8294\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 1s 651us/sample - loss: 0.5587 - acc: 0.7922\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 1s 657us/sample - loss: 0.4402 - acc: 0.8424\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 1s 683us/sample - loss: 0.4907 - acc: 0.8246\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 1s 646us/sample - loss: 0.5099 - acc: 0.8157\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 1s 644us/sample - loss: 0.4468 - acc: 0.8577\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 1s 648us/sample - loss: 0.4630 - acc: 0.8407\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 1s 679us/sample - loss: 0.3929 - acc: 0.8674\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 1s 669us/sample - loss: 0.3886 - acc: 0.8658\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 1s 698us/sample - loss: 0.4306 - acc: 0.8432\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 1s 668us/sample - loss: 0.6127 - acc: 0.7955\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 1s 665us/sample - loss: 0.4169 - acc: 0.8432\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 1s 679us/sample - loss: 0.3040 - acc: 0.8973\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 1s 682us/sample - loss: 0.3841 - acc: 0.8715\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 1s 658us/sample - loss: 0.3103 - acc: 0.8973\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 1s 664us/sample - loss: 0.3245 - acc: 0.8973\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 1s 657us/sample - loss: 0.2575 - acc: 0.9127\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 1s 665us/sample - loss: 0.2982 - acc: 0.8925\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 1s 663us/sample - loss: 0.3297 - acc: 0.8957\n",
            "412/412 [==============================] - 0s 401us/sample - loss: 1.1495 - acc: 0.6796\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 1s 762us/sample - loss: 3.2431 - acc: 0.0914\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 1s 708us/sample - loss: 2.2762 - acc: 0.1770\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 1s 676us/sample - loss: 2.1183 - acc: 0.2490\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 1s 681us/sample - loss: 1.9948 - acc: 0.2805\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 1s 670us/sample - loss: 1.7621 - acc: 0.3775\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 1s 686us/sample - loss: 1.7448 - acc: 0.3630\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 1s 684us/sample - loss: 1.6201 - acc: 0.4066\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 1s 667us/sample - loss: 1.5481 - acc: 0.4406\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 1s 677us/sample - loss: 1.3881 - acc: 0.4713\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 1s 678us/sample - loss: 1.2459 - acc: 0.5505\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 1s 670us/sample - loss: 1.2704 - acc: 0.5295\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 1s 678us/sample - loss: 1.1841 - acc: 0.5772\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 1s 676us/sample - loss: 1.0926 - acc: 0.6039\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 1s 662us/sample - loss: 1.0708 - acc: 0.6120\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 1s 677us/sample - loss: 0.9712 - acc: 0.6766\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 1s 674us/sample - loss: 0.9212 - acc: 0.6774\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 1s 676us/sample - loss: 0.8639 - acc: 0.6847\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 1s 683us/sample - loss: 0.7307 - acc: 0.7575\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 1s 700us/sample - loss: 0.7310 - acc: 0.7542\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 1s 674us/sample - loss: 0.7280 - acc: 0.7534\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 1s 680us/sample - loss: 0.7120 - acc: 0.7591\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 1s 655us/sample - loss: 0.7039 - acc: 0.7591\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 1s 669us/sample - loss: 0.6136 - acc: 0.8027\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 1s 668us/sample - loss: 0.7827 - acc: 0.7300\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 1s 652us/sample - loss: 0.6405 - acc: 0.7817\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 1s 687us/sample - loss: 0.5820 - acc: 0.8165\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 1s 693us/sample - loss: 0.6000 - acc: 0.7963\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 1s 674us/sample - loss: 0.8052 - acc: 0.7292\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 1s 694us/sample - loss: 0.7200 - acc: 0.7470\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 1s 691us/sample - loss: 0.7354 - acc: 0.7478\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 1s 672us/sample - loss: 0.5350 - acc: 0.8181\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 1s 668us/sample - loss: 0.5234 - acc: 0.8205\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 1s 668us/sample - loss: 0.4563 - acc: 0.8593\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 1s 670us/sample - loss: 0.4594 - acc: 0.8537\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 1s 674us/sample - loss: 0.4914 - acc: 0.8319\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 1s 685us/sample - loss: 0.3808 - acc: 0.8795\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 1s 704us/sample - loss: 0.4482 - acc: 0.8513\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 1s 676us/sample - loss: 0.4307 - acc: 0.8529\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 1s 699us/sample - loss: 0.6838 - acc: 0.7526\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 1s 702us/sample - loss: 0.8008 - acc: 0.7219\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 1s 699us/sample - loss: 0.6041 - acc: 0.7955\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 1s 679us/sample - loss: 0.4242 - acc: 0.8674\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 1s 679us/sample - loss: 0.5523 - acc: 0.8019\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 1s 695us/sample - loss: 0.5261 - acc: 0.8173\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 1s 745us/sample - loss: 0.4806 - acc: 0.8286\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 1s 707us/sample - loss: 0.5060 - acc: 0.8230\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 1s 686us/sample - loss: 0.5348 - acc: 0.8036\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 1s 702us/sample - loss: 0.3920 - acc: 0.8610\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 1s 672us/sample - loss: 0.3921 - acc: 0.8658\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 1s 665us/sample - loss: 0.4826 - acc: 0.8254\n",
            "412/412 [==============================] - 0s 378us/sample - loss: 0.8806 - acc: 0.7354\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 1s 785us/sample - loss: 3.5649 - acc: 0.1067\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 1s 693us/sample - loss: 2.4106 - acc: 0.1196\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 1s 705us/sample - loss: 2.2650 - acc: 0.1819\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 1s 687us/sample - loss: 2.1349 - acc: 0.2175\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 1s 713us/sample - loss: 1.9733 - acc: 0.2959\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 1s 703us/sample - loss: 1.8002 - acc: 0.3452\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 1s 705us/sample - loss: 1.7537 - acc: 0.3508\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 1s 693us/sample - loss: 1.4273 - acc: 0.4964\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 1s 703us/sample - loss: 1.3803 - acc: 0.5028\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 1s 701us/sample - loss: 1.3011 - acc: 0.5230\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 1s 697us/sample - loss: 1.2655 - acc: 0.5441\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 1s 691us/sample - loss: 1.2261 - acc: 0.5675\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 1s 707us/sample - loss: 1.1820 - acc: 0.5748\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 1s 695us/sample - loss: 1.1354 - acc: 0.5926\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 1s 717us/sample - loss: 1.1003 - acc: 0.6443\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 1s 708us/sample - loss: 0.9635 - acc: 0.6492\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 1s 724us/sample - loss: 0.9291 - acc: 0.6807\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 1s 706us/sample - loss: 0.9464 - acc: 0.6589\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 1s 716us/sample - loss: 0.8967 - acc: 0.6896\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 1s 706us/sample - loss: 0.7697 - acc: 0.7300\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 1s 722us/sample - loss: 0.7820 - acc: 0.7332\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 1s 690us/sample - loss: 0.6769 - acc: 0.7631\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 1s 710us/sample - loss: 0.6848 - acc: 0.7615\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 1s 715us/sample - loss: 0.7240 - acc: 0.7510\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 1s 735us/sample - loss: 0.6750 - acc: 0.7648\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 1s 704us/sample - loss: 0.7406 - acc: 0.7308\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 1s 708us/sample - loss: 0.6595 - acc: 0.7583\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 1s 727us/sample - loss: 0.6378 - acc: 0.7825\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 1s 712us/sample - loss: 0.6283 - acc: 0.7858\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 1s 718us/sample - loss: 0.5679 - acc: 0.7979\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 1s 713us/sample - loss: 0.6738 - acc: 0.7607\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 1s 720us/sample - loss: 0.5894 - acc: 0.7930\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 1s 708us/sample - loss: 0.4644 - acc: 0.8472\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 1s 696us/sample - loss: 0.6060 - acc: 0.7947\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 1s 682us/sample - loss: 0.6196 - acc: 0.7882\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 1s 707us/sample - loss: 0.4796 - acc: 0.8432\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 1s 687us/sample - loss: 0.4890 - acc: 0.8367\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 1s 684us/sample - loss: 0.6583 - acc: 0.7769\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 1s 684us/sample - loss: 0.5455 - acc: 0.8124\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 1s 699us/sample - loss: 0.6492 - acc: 0.7680\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 1s 711us/sample - loss: 0.4742 - acc: 0.8399\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 1s 690us/sample - loss: 0.4399 - acc: 0.8472\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 1s 699us/sample - loss: 0.4579 - acc: 0.8375\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 1s 721us/sample - loss: 0.3402 - acc: 0.8812\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 1s 691us/sample - loss: 0.4797 - acc: 0.8319\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 1s 706us/sample - loss: 0.5102 - acc: 0.8157\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 1s 705us/sample - loss: 0.5716 - acc: 0.7995\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 1s 725us/sample - loss: 0.3203 - acc: 0.8973\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 1s 691us/sample - loss: 0.2572 - acc: 0.9127\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 1s 680us/sample - loss: 0.2674 - acc: 0.9103\n",
            "412/412 [==============================] - 0s 391us/sample - loss: 0.7568 - acc: 0.7985\n",
            "Average Loss and Accuracy in Architecture3\n",
            "0.8624877267365406\n",
            "0.7537612468004227\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 183us/sample - loss: 0.6297 - acc: 0.7942\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.90        47\n",
            "           1       0.88      0.83      0.85        46\n",
            "           2       0.86      0.72      0.78        43\n",
            "           3       0.94      0.73      0.83        45\n",
            "           4       0.55      0.88      0.68        42\n",
            "           5       0.79      0.86      0.82        35\n",
            "           6       0.73      0.80      0.76        44\n",
            "           7       0.71      0.71      0.71        34\n",
            "           8       0.88      0.70      0.78        40\n",
            "           9       0.86      0.84      0.85        37\n",
            "\n",
            "    accuracy                           0.79       413\n",
            "   macro avg       0.81      0.79      0.80       413\n",
            "weighted avg       0.82      0.79      0.80       413\n",
            "\n",
            "Train on 1236 samples\n",
            "Epoch 1/50\n",
            "1236/1236 [==============================] - 0s 402us/sample - loss: 2.3538 - acc: 0.1003\n",
            "Epoch 2/50\n",
            "1236/1236 [==============================] - 0s 286us/sample - loss: 2.3224 - acc: 0.0963\n",
            "Epoch 3/50\n",
            "1236/1236 [==============================] - 0s 295us/sample - loss: 2.2852 - acc: 0.1408\n",
            "Epoch 4/50\n",
            "1236/1236 [==============================] - 0s 277us/sample - loss: 2.2490 - acc: 0.1602\n",
            "Epoch 5/50\n",
            "1236/1236 [==============================] - 0s 285us/sample - loss: 2.0568 - acc: 0.2225\n",
            "Epoch 6/50\n",
            "1236/1236 [==============================] - 0s 273us/sample - loss: 2.0952 - acc: 0.2184\n",
            "Epoch 7/50\n",
            "1236/1236 [==============================] - 0s 261us/sample - loss: 1.9929 - acc: 0.2832\n",
            "Epoch 8/50\n",
            "1236/1236 [==============================] - 0s 278us/sample - loss: 1.7082 - acc: 0.3552\n",
            "Epoch 9/50\n",
            "1236/1236 [==============================] - 0s 278us/sample - loss: 1.6009 - acc: 0.4053\n",
            "Epoch 10/50\n",
            "1236/1236 [==============================] - 0s 280us/sample - loss: 1.5587 - acc: 0.3892\n",
            "Epoch 11/50\n",
            "1236/1236 [==============================] - 0s 289us/sample - loss: 1.4417 - acc: 0.4612\n",
            "Epoch 12/50\n",
            "1236/1236 [==============================] - 0s 282us/sample - loss: 1.3602 - acc: 0.4701\n",
            "Epoch 13/50\n",
            "1236/1236 [==============================] - 0s 282us/sample - loss: 1.3504 - acc: 0.4911\n",
            "Epoch 14/50\n",
            "1236/1236 [==============================] - 0s 283us/sample - loss: 1.2898 - acc: 0.5049\n",
            "Epoch 15/50\n",
            "1236/1236 [==============================] - 0s 279us/sample - loss: 1.2054 - acc: 0.5299\n",
            "Epoch 16/50\n",
            "1236/1236 [==============================] - 0s 274us/sample - loss: 1.1606 - acc: 0.5639\n",
            "Epoch 17/50\n",
            "1236/1236 [==============================] - 0s 293us/sample - loss: 1.3121 - acc: 0.5008\n",
            "Epoch 18/50\n",
            "1236/1236 [==============================] - 0s 281us/sample - loss: 1.1952 - acc: 0.5477\n",
            "Epoch 19/50\n",
            "1236/1236 [==============================] - 0s 274us/sample - loss: 1.0883 - acc: 0.5947\n",
            "Epoch 20/50\n",
            "1236/1236 [==============================] - 0s 308us/sample - loss: 1.0558 - acc: 0.6165\n",
            "Epoch 21/50\n",
            "1236/1236 [==============================] - 0s 293us/sample - loss: 1.1535 - acc: 0.5485\n",
            "Epoch 22/50\n",
            "1236/1236 [==============================] - 0s 286us/sample - loss: 1.1158 - acc: 0.5744\n",
            "Epoch 23/50\n",
            "1236/1236 [==============================] - 0s 275us/sample - loss: 1.0827 - acc: 0.5833\n",
            "Epoch 24/50\n",
            "1236/1236 [==============================] - 0s 310us/sample - loss: 1.0947 - acc: 0.5752\n",
            "Epoch 25/50\n",
            "1236/1236 [==============================] - 0s 281us/sample - loss: 1.2196 - acc: 0.5477\n",
            "Epoch 26/50\n",
            "1236/1236 [==============================] - 0s 309us/sample - loss: 1.1497 - acc: 0.5526\n",
            "Epoch 27/50\n",
            "1236/1236 [==============================] - 0s 279us/sample - loss: 0.9078 - acc: 0.6731\n",
            "Epoch 28/50\n",
            "1236/1236 [==============================] - 0s 279us/sample - loss: 1.0319 - acc: 0.6133\n",
            "Epoch 29/50\n",
            "1236/1236 [==============================] - 0s 280us/sample - loss: 0.9274 - acc: 0.6537\n",
            "Epoch 30/50\n",
            "1236/1236 [==============================] - 0s 282us/sample - loss: 0.8744 - acc: 0.6739\n",
            "Epoch 31/50\n",
            "1236/1236 [==============================] - 0s 284us/sample - loss: 0.8928 - acc: 0.6820\n",
            "Epoch 32/50\n",
            "1236/1236 [==============================] - 0s 304us/sample - loss: 0.8998 - acc: 0.6707\n",
            "Epoch 33/50\n",
            "1236/1236 [==============================] - 0s 287us/sample - loss: 0.9262 - acc: 0.6610\n",
            "Epoch 34/50\n",
            "1236/1236 [==============================] - 0s 273us/sample - loss: 0.7844 - acc: 0.7249\n",
            "Epoch 35/50\n",
            "1236/1236 [==============================] - 0s 280us/sample - loss: 0.7623 - acc: 0.7225\n",
            "Epoch 36/50\n",
            "1236/1236 [==============================] - 0s 278us/sample - loss: 0.7917 - acc: 0.7136\n",
            "Epoch 37/50\n",
            "1236/1236 [==============================] - 0s 277us/sample - loss: 0.7448 - acc: 0.7403\n",
            "Epoch 38/50\n",
            "1236/1236 [==============================] - 0s 273us/sample - loss: 0.8396 - acc: 0.6926\n",
            "Epoch 39/50\n",
            "1236/1236 [==============================] - 0s 286us/sample - loss: 0.8634 - acc: 0.6869\n",
            "Epoch 40/50\n",
            "1236/1236 [==============================] - 0s 264us/sample - loss: 0.7131 - acc: 0.7524\n",
            "Epoch 41/50\n",
            "1236/1236 [==============================] - 0s 283us/sample - loss: 0.8098 - acc: 0.7079\n",
            "Epoch 42/50\n",
            "1236/1236 [==============================] - 0s 285us/sample - loss: 0.7087 - acc: 0.7443\n",
            "Epoch 43/50\n",
            "1236/1236 [==============================] - 0s 289us/sample - loss: 0.7077 - acc: 0.7451\n",
            "Epoch 44/50\n",
            "1236/1236 [==============================] - 0s 289us/sample - loss: 0.6078 - acc: 0.7921\n",
            "Epoch 45/50\n",
            "1236/1236 [==============================] - 0s 288us/sample - loss: 0.6663 - acc: 0.7646\n",
            "Epoch 46/50\n",
            "1236/1236 [==============================] - 0s 267us/sample - loss: 0.7589 - acc: 0.7330\n",
            "Epoch 47/50\n",
            "1236/1236 [==============================] - 0s 282us/sample - loss: 0.6635 - acc: 0.7662\n",
            "Epoch 48/50\n",
            "1236/1236 [==============================] - 0s 280us/sample - loss: 0.5941 - acc: 0.8026\n",
            "Epoch 49/50\n",
            "1236/1236 [==============================] - 0s 271us/sample - loss: 0.6134 - acc: 0.7888\n",
            "Epoch 50/50\n",
            "1236/1236 [==============================] - 0s 300us/sample - loss: 0.6813 - acc: 0.7662\n",
            "413/413 [==============================] - 0s 336us/sample - loss: 0.8009 - acc: 0.7240\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 1s 405us/sample - loss: 2.3613 - acc: 0.1083\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 301us/sample - loss: 2.3126 - acc: 0.0914\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 2.3027 - acc: 0.1035\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 277us/sample - loss: 2.3016 - acc: 0.1205\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 289us/sample - loss: 2.2903 - acc: 0.1124\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 283us/sample - loss: 2.1650 - acc: 0.1649\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 262us/sample - loss: 2.0283 - acc: 0.1964\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 1.9326 - acc: 0.2191\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 285us/sample - loss: 1.8995 - acc: 0.2361\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 1.8874 - acc: 0.2280\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 1.8120 - acc: 0.2555\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 274us/sample - loss: 1.7977 - acc: 0.2732\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 265us/sample - loss: 1.7258 - acc: 0.2732\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 280us/sample - loss: 1.8138 - acc: 0.2668\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 1.7407 - acc: 0.2935\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 274us/sample - loss: 1.7208 - acc: 0.2862\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 296us/sample - loss: 1.7315 - acc: 0.2991\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 284us/sample - loss: 1.7535 - acc: 0.3040\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 277us/sample - loss: 1.6644 - acc: 0.3209\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 269us/sample - loss: 1.7056 - acc: 0.3339\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 268us/sample - loss: 1.6430 - acc: 0.3331\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 1.6256 - acc: 0.3395\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 1.5819 - acc: 0.3937\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 272us/sample - loss: 1.6134 - acc: 0.3646\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 258us/sample - loss: 1.5326 - acc: 0.4058\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 271us/sample - loss: 1.6053 - acc: 0.3751\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 299us/sample - loss: 1.5433 - acc: 0.4276\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 287us/sample - loss: 1.4758 - acc: 0.4430\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 287us/sample - loss: 1.4862 - acc: 0.4470\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 273us/sample - loss: 1.3929 - acc: 0.4826\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 1.4388 - acc: 0.4673\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 266us/sample - loss: 1.3389 - acc: 0.5020\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 1.3904 - acc: 0.4826\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 269us/sample - loss: 1.3179 - acc: 0.5190\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 1.3318 - acc: 0.5222\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 1.2097 - acc: 0.5796\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 267us/sample - loss: 1.2176 - acc: 0.5408\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 286us/sample - loss: 1.3672 - acc: 0.4947\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 283us/sample - loss: 1.2861 - acc: 0.5311\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 276us/sample - loss: 1.1433 - acc: 0.5901\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 289us/sample - loss: 1.2622 - acc: 0.5335\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 283us/sample - loss: 1.2535 - acc: 0.5424\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 1.1660 - acc: 0.5756\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 284us/sample - loss: 1.1247 - acc: 0.6095\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 275us/sample - loss: 1.2338 - acc: 0.5618\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 283us/sample - loss: 1.1701 - acc: 0.5732\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 274us/sample - loss: 1.1698 - acc: 0.5675\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 276us/sample - loss: 1.1808 - acc: 0.5756\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 264us/sample - loss: 1.1178 - acc: 0.5869\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 286us/sample - loss: 1.0579 - acc: 0.6136\n",
            "412/412 [==============================] - 0s 355us/sample - loss: 1.4905 - acc: 0.5194\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 1s 426us/sample - loss: 2.3554 - acc: 0.0930\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 2.3277 - acc: 0.1172\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 339us/sample - loss: 2.3047 - acc: 0.1035\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 302us/sample - loss: 2.2729 - acc: 0.1350\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 301us/sample - loss: 2.1459 - acc: 0.1787\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 303us/sample - loss: 2.0202 - acc: 0.2086\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 289us/sample - loss: 1.9046 - acc: 0.2506\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 2.0002 - acc: 0.2320\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 284us/sample - loss: 1.9077 - acc: 0.2538\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 286us/sample - loss: 1.8660 - acc: 0.2619\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 290us/sample - loss: 1.8933 - acc: 0.2474\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 286us/sample - loss: 1.6645 - acc: 0.3484\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 279us/sample - loss: 1.7777 - acc: 0.3161\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 287us/sample - loss: 1.5177 - acc: 0.3969\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 288us/sample - loss: 1.4898 - acc: 0.4139\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 282us/sample - loss: 1.3372 - acc: 0.4762\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 1.2695 - acc: 0.5117\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 1.3334 - acc: 0.4616\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 277us/sample - loss: 1.2356 - acc: 0.5061\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 1.3904 - acc: 0.4462\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 1.2125 - acc: 0.5255\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 285us/sample - loss: 1.3093 - acc: 0.4923\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 1.1448 - acc: 0.5408\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 317us/sample - loss: 1.1116 - acc: 0.5643\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 288us/sample - loss: 1.1442 - acc: 0.5481\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 1.0599 - acc: 0.5780\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 1.0432 - acc: 0.5724\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 306us/sample - loss: 1.3951 - acc: 0.4867\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 279us/sample - loss: 1.2087 - acc: 0.5327\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 285us/sample - loss: 1.0497 - acc: 0.5869\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 305us/sample - loss: 1.1733 - acc: 0.5513\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 1.0386 - acc: 0.5966\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 299us/sample - loss: 1.0207 - acc: 0.5966\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 304us/sample - loss: 1.0912 - acc: 0.5667\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 284us/sample - loss: 0.9393 - acc: 0.6281\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 283us/sample - loss: 0.9923 - acc: 0.6120\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 282us/sample - loss: 1.0858 - acc: 0.5877\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 284us/sample - loss: 1.0410 - acc: 0.5845\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 295us/sample - loss: 1.2416 - acc: 0.5141\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 289us/sample - loss: 1.0698 - acc: 0.6225\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 278us/sample - loss: 0.9578 - acc: 0.6467\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 288us/sample - loss: 0.8865 - acc: 0.6669\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 301us/sample - loss: 0.9282 - acc: 0.6322\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 1.0239 - acc: 0.5926\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 294us/sample - loss: 0.8960 - acc: 0.6613\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 286us/sample - loss: 0.9915 - acc: 0.6257\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 298us/sample - loss: 0.9952 - acc: 0.6120\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 300us/sample - loss: 0.8598 - acc: 0.6766\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 281us/sample - loss: 0.9923 - acc: 0.6241\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 295us/sample - loss: 0.7776 - acc: 0.7082\n",
            "412/412 [==============================] - 0s 393us/sample - loss: 1.2020 - acc: 0.5898\n",
            "Train on 1237 samples\n",
            "Epoch 1/50\n",
            "1237/1237 [==============================] - 1s 425us/sample - loss: 2.3765 - acc: 0.1027\n",
            "Epoch 2/50\n",
            "1237/1237 [==============================] - 0s 304us/sample - loss: 2.3182 - acc: 0.0986\n",
            "Epoch 3/50\n",
            "1237/1237 [==============================] - 0s 287us/sample - loss: 2.3071 - acc: 0.1011\n",
            "Epoch 4/50\n",
            "1237/1237 [==============================] - 0s 309us/sample - loss: 2.2865 - acc: 0.1463\n",
            "Epoch 5/50\n",
            "1237/1237 [==============================] - 0s 287us/sample - loss: 2.2154 - acc: 0.1746\n",
            "Epoch 6/50\n",
            "1237/1237 [==============================] - 0s 303us/sample - loss: 2.0392 - acc: 0.2231\n",
            "Epoch 7/50\n",
            "1237/1237 [==============================] - 0s 288us/sample - loss: 1.8996 - acc: 0.2902\n",
            "Epoch 8/50\n",
            "1237/1237 [==============================] - 0s 306us/sample - loss: 1.8069 - acc: 0.3193\n",
            "Epoch 9/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 1.6751 - acc: 0.3638\n",
            "Epoch 10/50\n",
            "1237/1237 [==============================] - 0s 289us/sample - loss: 1.6019 - acc: 0.3921\n",
            "Epoch 11/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 1.5365 - acc: 0.4220\n",
            "Epoch 12/50\n",
            "1237/1237 [==============================] - 0s 313us/sample - loss: 1.4822 - acc: 0.4365\n",
            "Epoch 13/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 1.3913 - acc: 0.4770\n",
            "Epoch 14/50\n",
            "1237/1237 [==============================] - 0s 306us/sample - loss: 1.4615 - acc: 0.4559\n",
            "Epoch 15/50\n",
            "1237/1237 [==============================] - 0s 294us/sample - loss: 1.2667 - acc: 0.5190\n",
            "Epoch 16/50\n",
            "1237/1237 [==============================] - 0s 301us/sample - loss: 1.2712 - acc: 0.5352\n",
            "Epoch 17/50\n",
            "1237/1237 [==============================] - 0s 302us/sample - loss: 1.1777 - acc: 0.5837\n",
            "Epoch 18/50\n",
            "1237/1237 [==============================] - 0s 307us/sample - loss: 1.2099 - acc: 0.5449\n",
            "Epoch 19/50\n",
            "1237/1237 [==============================] - 0s 294us/sample - loss: 1.1466 - acc: 0.5651\n",
            "Epoch 20/50\n",
            "1237/1237 [==============================] - 0s 325us/sample - loss: 1.2948 - acc: 0.5368\n",
            "Epoch 21/50\n",
            "1237/1237 [==============================] - 0s 311us/sample - loss: 0.9868 - acc: 0.6427\n",
            "Epoch 22/50\n",
            "1237/1237 [==============================] - 0s 308us/sample - loss: 0.9568 - acc: 0.6677\n",
            "Epoch 23/50\n",
            "1237/1237 [==============================] - 0s 299us/sample - loss: 0.9376 - acc: 0.6613\n",
            "Epoch 24/50\n",
            "1237/1237 [==============================] - 0s 310us/sample - loss: 1.0703 - acc: 0.6095\n",
            "Epoch 25/50\n",
            "1237/1237 [==============================] - 0s 312us/sample - loss: 0.9939 - acc: 0.6314\n",
            "Epoch 26/50\n",
            "1237/1237 [==============================] - 0s 298us/sample - loss: 0.9604 - acc: 0.6492\n",
            "Epoch 27/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 0.9089 - acc: 0.6645\n",
            "Epoch 28/50\n",
            "1237/1237 [==============================] - 0s 312us/sample - loss: 1.0957 - acc: 0.6168\n",
            "Epoch 29/50\n",
            "1237/1237 [==============================] - 0s 304us/sample - loss: 0.9895 - acc: 0.6492\n",
            "Epoch 30/50\n",
            "1237/1237 [==============================] - 0s 300us/sample - loss: 0.9365 - acc: 0.6694\n",
            "Epoch 31/50\n",
            "1237/1237 [==============================] - 0s 296us/sample - loss: 0.8556 - acc: 0.6993\n",
            "Epoch 32/50\n",
            "1237/1237 [==============================] - 0s 314us/sample - loss: 0.8329 - acc: 0.6920\n",
            "Epoch 33/50\n",
            "1237/1237 [==============================] - 0s 303us/sample - loss: 0.8307 - acc: 0.7154\n",
            "Epoch 34/50\n",
            "1237/1237 [==============================] - 0s 308us/sample - loss: 0.7924 - acc: 0.7098\n",
            "Epoch 35/50\n",
            "1237/1237 [==============================] - 0s 296us/sample - loss: 0.7291 - acc: 0.7478\n",
            "Epoch 36/50\n",
            "1237/1237 [==============================] - 0s 294us/sample - loss: 0.6933 - acc: 0.7591\n",
            "Epoch 37/50\n",
            "1237/1237 [==============================] - 0s 290us/sample - loss: 0.6293 - acc: 0.7753\n",
            "Epoch 38/50\n",
            "1237/1237 [==============================] - 0s 291us/sample - loss: 0.7647 - acc: 0.7203\n",
            "Epoch 39/50\n",
            "1237/1237 [==============================] - 0s 296us/sample - loss: 0.6117 - acc: 0.7922\n",
            "Epoch 40/50\n",
            "1237/1237 [==============================] - 0s 301us/sample - loss: 0.6901 - acc: 0.7672\n",
            "Epoch 41/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 0.7004 - acc: 0.7486\n",
            "Epoch 42/50\n",
            "1237/1237 [==============================] - 0s 307us/sample - loss: 0.5845 - acc: 0.7955\n",
            "Epoch 43/50\n",
            "1237/1237 [==============================] - 0s 299us/sample - loss: 0.8630 - acc: 0.6920\n",
            "Epoch 44/50\n",
            "1237/1237 [==============================] - 0s 292us/sample - loss: 0.7822 - acc: 0.7227\n",
            "Epoch 45/50\n",
            "1237/1237 [==============================] - 0s 293us/sample - loss: 0.5742 - acc: 0.8027\n",
            "Epoch 46/50\n",
            "1237/1237 [==============================] - 0s 293us/sample - loss: 0.6573 - acc: 0.7656\n",
            "Epoch 47/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 0.6545 - acc: 0.7696\n",
            "Epoch 48/50\n",
            "1237/1237 [==============================] - 0s 297us/sample - loss: 0.6707 - acc: 0.7599\n",
            "Epoch 49/50\n",
            "1237/1237 [==============================] - 0s 290us/sample - loss: 0.5121 - acc: 0.8189\n",
            "Epoch 50/50\n",
            "1237/1237 [==============================] - 0s 317us/sample - loss: 0.5524 - acc: 0.8149\n",
            "412/412 [==============================] - 0s 396us/sample - loss: 0.7971 - acc: 0.7500\n",
            "Average Loss and Accuracy in Architecture4\n",
            "1.0726553794814422\n",
            "0.6457985639572144\n",
            "Evaluate testing part\n",
            "413/413 [==============================] - 0s 118us/sample - loss: 0.9003 - acc: 0.6901\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.64      0.77        47\n",
            "           1       0.93      0.61      0.74        46\n",
            "           2       0.70      0.65      0.67        43\n",
            "           3       0.80      0.82      0.81        45\n",
            "           4       0.51      0.62      0.56        42\n",
            "           5       0.82      0.91      0.86        35\n",
            "           6       0.52      0.52      0.52        44\n",
            "           7       0.44      0.53      0.48        34\n",
            "           8       0.62      0.75      0.68        40\n",
            "           9       0.77      0.89      0.82        37\n",
            "\n",
            "    accuracy                           0.69       413\n",
            "   macro avg       0.71      0.69      0.69       413\n",
            "weighted avg       0.72      0.69      0.69       413\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}